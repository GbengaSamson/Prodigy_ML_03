# -*- coding: utf-8 -*-
"""Prodigy_ML_03.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ybk3jhsv0jIZXnNp6-mQVK7_h1kYQp8J
"""

#installing the Kaggle library
!pip install kaggle

# configuring the path of Kaggle.json file
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

#from google.colab import drive
#drive.mount('/content/drive')

"""Importing the DOG vs CAT Dataset from kaggle

"""

# Kaggle api
!kaggle competitions download -c dogs-vs-cats

!ls

#Extracting the compressed dataset
from zipfile import  ZipFile

dataset = '/content/dogs-vs-cats.zip'

with ZipFile(dataset, 'r') as zip:
  zip.extractall()
  print('The dataset is Extracted')

#Extracting the compressed dataset
from zipfile import  ZipFile

dataset = '/content/train.zip'

with ZipFile(dataset, 'r') as zip:
  zip.extractall()
  print('The dataset is Extracted')

import os
#counting the number of files in train folder
path, dirs, files = next(os.walk('/content/train'))
file_count = len(files)
print('number of images:', file_count)

"""Printing the name of images"""

file_names = os.listdir('/content/train')
print(file_names)

"""importint the Dependancies"""

import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from sklearn.model_selection import train_test_split
from google.colab.patches import cv2_imshow

"""Displaying the images of dogs and cat"""

#display DoG image
img = mpimg.imread('/content/train/dog.9285.jpg')
imgplt = plt.imshow(img)
plt.show()

#display Cat image
img = mpimg.imread('/content/train/cat.8227.jpg')
imgplt = plt.imshow(img)
plt.show()

file_names = os.listdir('/content/train')

for i in range(5):

  name =  file_names[i]

  print(name[0:3])

file_names = os.listdir('/content/train')

dog_count = 0

cat_count = 0

for img_file in file_names:
  name = img_file[0:3]

  if name == 'dog':
    dog_count += 1

  else:
    cat_count += 1

print('Number of dog images =', dog_count)
print('Number of cat images =', cat_count)

"""Resizing all the images"""

#Creating a directory for resized images
os.mkdir('/content/image resized')

original_folder = '/content/train/'
resized_folder = '/content/image resized/'

for i in range(2000):

  filename = os.listdir(original_folder)[i]
  img_path = original_folder + filename

  img = Image.open(img_path)
  img = img.resize((224,224))
  img = img.convert('RGB')

  newImgPath =  resized_folder + filename
  img.save(newImgPath)

#display resized DoG image
img = mpimg.imread('/content/image resized/dog.6066.jpg')
imgplt = plt.imshow(img)
plt.show()

#display resized DoG image
img = mpimg.imread('/content/image resized/cat.8227.jpg')
imgplt = plt.imshow(img)
plt.show()

"""Creating labels for resized images of dog and cat

Cat ..... > 0
Dog ..... > 1
"""

#Creating a for loop to assign labels
filenames = os.listdir('/content/image resized/')
labels = []

for i in range(2000):

  file_name = filenames[i]
  label = file_name[0:3]

  if label == 'dog':
    labels.append(1)

  else:
    labels.append(0)

print(filenames[0:5])
print(len(filenames))

print(labels[0:5])
print(len(labels))

#Counting the images of dogs and cats out of 2000 images
values, counts = np.unique(labels, return_counts = True)
print(values)
print(counts)

"""Converting all the resized images to numpy arrays"""

import cv2
import glob

image_directory = '/content/image resized/'
image_extension = ['png', 'jpg']

files = []

[files.extend(glob.glob(image_directory + '*.' + e)) for e in image_extension]

dog_cat_images = np.asarray([cv2.imread(file) for file in files])

dog_cat_images

type(dog_cat_images)

print(dog_cat_images.shape)

X = dog_cat_images
Y = np.asarray(labels)

Y

"""Train Test Split"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42 )

print(X.shape, X_train.shape, X_test.shape)

"""1600 ...> Training Images
400 ....> Test Images
"""

#Scaling the Data
X_train_scaled = X_train/1

X_test_scaled = X_test/1

Y_train_scaled = Y_train/1

Y_test_scaled = Y_test/1

Y_train_scaled

"""print("Flattening images...")
images_ reshape = X_train_scaled.reshape(len(X_train_scaled), -1)
print(f"Flattened images shape: {images_flat.shape}")
"""

print("Flattening images...")
X_Timages_reshape = X_train_scaled.reshape(len(X_train_scaled), -2)
print(f"Flattened images shape: {X_Timages_reshape.shape}")

print("Flattening images...")
X_Ttimages_reshape = X_test_scaled.reshape(len(X_test_scaled), -2)
print(f"Flattened images shape: {X_Ttimages_reshape.shape}")

print("Flattening images...")
YTtimages_reshape = Y_test_scaled.reshape(len(Y_test_scaled), -2)
print(f"Flattened images shape: {YTtimages_reshape.shape}")

print("Flattening images...")
Y_Timages_reshape = Y_train_scaled.reshape(len(Y_train_scaled), -2)
print(f"Flattened images shape: {Y_Timages_reshape.shape}")

#print(X_train_scaled)

"""Building the Support Vector Machine Model"""

from sklearn.svm import SVC
from sklearn.preprocessing import KBinsDiscretizer
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

print("Training SVM model...")
svm = SVC(kernel='linear')
svm.fit(X_Timages_reshape, Y_train)
print("SVM model trained.")

# Step 6: Evaluate Model
print("Evaluating model...")
y_pred = svm.predict(X_Ttimages_reshape)

accuracy = accuracy_score(Y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

print('Classification Report:')
print(classification_report(Y_test, y_pred, target_names =filenames))

print('Confusion Matrix:')
print(confusion_matrix(Y_test, y_pred))